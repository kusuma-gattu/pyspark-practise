{"cells": [{"cell_type": "code", "execution_count": 2, "id": "29bd2741-aefb-4f0b-8cf3-4f4c8b8596ae", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/08/01 16:00:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- campaign_country: string (nullable = true)\n |-- campaign_id: string (nullable = true)\n |-- campaign_name: string (nullable = true)\n |-- device_type: string (nullable = true)\n |-- event_time: string (nullable = true)\n |-- event_type: string (nullable = true)\n |-- os_type: string (nullable = true)\n |-- place_id: string (nullable = true)\n |-- user_id: string (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n|campaign_country|campaign_id|       campaign_name|device_type|          event_time|event_type|os_type| place_id|            user_id|\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n|             USA|    ABCDFAE|Food category tar...|      apple|2018-10-12T13:10:...|impression|    ios|CASSBB-11|1264374214654454321|\n|             USA|    ABCDFAE|Food category tar...|   MOTOROLA|2018-10-12T13:09:...|impression|android|CADGBD-13|1674374214654454321|\n|             USA|    ABCDFAE|Food category tar...|    SAMSUNG|2018-10-12T13:10:...|  video ad|android|BADGBA-12|   5747421465445443|\n|             USA|    ABCDFAE|Food category tar...|    SAMSUNG|2018-10-12T13:10:...|     click|android|CASSBB-11|1864374214654454132|\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n\n"}], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\nspark = SparkSession.builder \\\n        .appName(\"ad_campaign_analysis\") \\\n        .getOrCreate()\n\nad_path = \"/tmp/spark_assignment_data/ad_campaigns_data.json\"\n\nad_df = spark.read.option('multiline', 'true').json(ad_path)\nad_df.printSchema()\nad_df.show(10)"}, {"cell_type": "code", "execution_count": 3, "id": "cbee34af-3cbd-45b2-8505-87ed1547a235", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+--------------------+-------+------+-------------------+\n|age_group|            category|country|gender|            user_id|\n+---------+--------------------+-------+------+-------------------+\n|    18-25|  [shopper, student]|    USA|  male|1264374214654454321|\n|    25-50|            [parent]|    USA|female|1674374214654454321|\n|    25-50|[shopper, parent,...|    USA|  male|   5747421465445443|\n|      50+|      [professional]|    USA|  male|1864374214654454132|\n|    18-25|  [shopper, student]|    USA|female|  14537421465445443|\n|      50+|[shopper, profess...|    USA|female|  25547421465445443|\n+---------+--------------------+-------+------+-------------------+\n\n"}], "source": "# hdfs file path\nuser_profile_path = \"/tmp/spark_assignment_data/user_profile_data.json\"\n\n# read user profile json data\nup_df = spark.read.option(\"multiline\", \"true\").json(user_profile_path)\nup_df.show()"}, {"cell_type": "code", "execution_count": 3, "id": "050c5eb2-428c-46c4-976d-502c1e784dbe", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------+\n|           place_ids|   store_name|\n+--------------------+-------------+\n|[CASSBB-11, CADGB...|     McDonald|\n|         [CASSBB-11]|   BurgerKing|\n|[BADGBA-13, CASSB...|        Macys|\n|         [BADGBA-12]|shoppers stop|\n+--------------------+-------------+\n\n"}], "source": "store_file_path = \"/tmp/spark_assignment_data/store_data.json\"\n\nst_df = spark.read.option(\"multiline\", \"true\").json(store_file_path)\nst_df.show()"}, {"cell_type": "code", "execution_count": 5, "id": "e6059b4b-7997-4a62-be33-0159ba0c3cb7", "metadata": {"tags": []}, "outputs": [], "source": "# extract date, hour column from event_time of ad compaign dataframe\n\nad_df1 = ad_df.withColumn(\"event_time\", F.col(\"event_time\").cast(\"timestamp\"))\nad_df2 = ad_df1.withColumn(\"date\", F.to_date(\"event_time\")) \\\n                .withColumn(\"hour\", F.hour(\"event_time\"))\n"}, {"cell_type": "code", "execution_count": 9, "id": "dc3b4b03-05e9-4165-a2a9-bed1fa3d66d7", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+-------+---------+\n|campaign_id|      date|hour|os_type|    event|\n+-----------+----------+----+-------+---------+\n|    ABCDFAE|2018-10-12|  13|android|{1, 1, 1}|\n|    ABCDFAE|2018-10-12|  13|    ios|{1, 0, 0}|\n+-----------+----------+----+-------+---------+\n\n"}], "source": "#  Analyse data for each campaign_id, date, hour, os_type & value to get all  the events with counts\n\n\nad_df3 = ad_df2.groupBy(\"campaign_id\", \"date\", \"hour\", \"os_type\", \"event_type\") \\\n            .agg(F.count(\"event_type\").alias(\"event_count\")) \\\n            .groupBy(\"campaign_id\", \"date\", \"hour\", \"os_type\") \\\n            .pivot(\"event_type\") \\\n            .agg(F.first(\"event_count\")) \\\n            .fillna(0) \\\n            .select(\n                \"campaign_id\",\n                \"date\",\n                \"hour\",\n                \"os_type\",\n                F.struct(\n                    F.col(\"impression\").alias(\"impression\"),\n                    F.col(\"click\").alias(\"click\"),\n                    F.col(\"video ad\").alias(\"video ad\")\n                ).alias(\"event\")\n)\n\nad_df3.show()\n\n                "}, {"cell_type": "code", "execution_count": 10, "id": "e023c96a-e7dd-43b2-9264-a26ee718a2f4", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# save the results to HDFS \nad_df3.write.json(\"/tmp/output_data/market_analysis1/\", mode=\"overwrite\")"}, {"cell_type": "code", "execution_count": 19, "id": "2a0c43b3-a718-435d-b41d-30d24343be98", "metadata": {"tags": []}, "outputs": [], "source": "# Analyse data for each campaign_id, date, hour, store_name & value to get all the events with counts\n\n# STEP1: get individual elements from place_ids, then drop place_ids column \nst_explode_df = st_df.withColumn(\"place_id\", F.explode(\"place_ids\")).drop(\"place_ids\")\n\n# STEP2: join the ad campaign and store explode dataframes\ncampaign_store_join_df = ad_df2.join(st_explode_df, on=\"place_id\", how=\"inner\") \\\n                    .select(\"campaign_id\",\n                            \"date\",\n                            \"hour\",\n                            \"event_type\",\n                            \"store_name\"\n                           )\nmarket_analysis2 = campaign_store_join_df.groupBy(\"campaign_id\", \"date\", \"hour\", \"store_name\", \"event_type\") \\\n                    .agg(F.count(\"event_type\").alias(\"event_count\")) \\\n                    .groupBy(\"campaign_id\", \"date\", \"hour\", \"store_name\") \\\n                    .pivot(\"event_type\") \\\n                    .agg(F.first(\"event_count\")) \\\n                    .fillna(0) \\\n                    .select(\n                        \"campaign_id\",\n                        \"date\",\n                        \"hour\",\n                        \"store_name\",\n                        F.struct(\n                            F.col(\"click\").alias(\"click\"),\n                            F.col(\"impression\").alias(\"impression\"),\n                            F.col(\"video ad\").alias(\"video ad\")\n                        ).alias(\"event\")\n                    )\n# STEP3: write the output to HDFS \nmarket_analysis2.write.json(\"/tmp/output_data/market_anlysis2/\", mode=\"overwrite\")\n            "}, {"cell_type": "code", "execution_count": 10, "id": "7a3c2628-7cd1-4321-80ee-eb139c601cda", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Analyse data for each campaign_id, date, hour, gender_type & value to get all the events with counts\n\n# STEP 1: join the campaign dataframe with user profile data \ncampaign_user_df = ad_df2.join(up_df, on=\"user_id\", how=\"inner\") \\\n                    .select(\n                        \"campaign_id\",\n                        \"date\",\n                        \"hour\",\n                        \"event_type\",\n                        \"gender\"\n                    )\n                       \n# STEP2: do analysis\nmarket_analysis3 = campaign_user_df.groupBy(\"campaign_id\", \"date\", \"hour\", \"event_type\", \"gender\" ) \\\n                    .agg(F.count(\"event_type\").alias(\"event_count\")) \\\n                    .groupBy(\"campaign_id\", \"date\", \"hour\", \"gender\") \\\n                    .pivot(\"event_type\") \\\n                    .agg(F.first(\"event_count\")) \\\n                    .fillna(0) \\\n                    .select(\n                        \"campaign_id\",\n                        \"date\",\n                        \"hour\",\n                        \"gender\",\n                        F.struct(\n                            F.col(\"click\").alias(\"click\"),\n                            F.col(\"impression\").alias(\"impression\"),\n                            F.col(\"video ad\").alias(\"video ad\")\n                        ).alias(\"event\")\n)\n\n# STEP3: write output to HDFS\nmarket_analysis3.write.json(\"/tmp/output_data/market_analysis3/\", mode=\"overwrite\")    "}, {"cell_type": "code", "execution_count": null, "id": "62dd13cc-ff49-40c6-908d-7cac9975eba2", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "f432af6e-8964-492a-863a-f53c2026cddc", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}